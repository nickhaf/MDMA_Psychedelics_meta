---
title: "MDMA/Psychadelics multi-level meta analysis"
author: Nicklas Hafiz
date: "`r format(Sys.time(), '%d %B, %Y')`"
format: 
  html:
    toc: true
    toc-depth: 3
    theme: sandstone
    embed-resources: true
bibliography:
  - grateful-refs.bib
  - references.bib
---

```{r load packages}
#| warning: false
#| message: false
#| echo: false

file_sources <- list.files(
  path = here::here("R"),
  pattern = "*.R"
)
source(here::here("R", file_sources[1]))
source(here::here("R", file_sources[2]))
```

CAUTION: I added the moderator variable last minute and didn't have a chance to check everything properly. 

# Introduction
The analysis follows the chapter [Fitting Three-Level Meta-Analysis Models in R](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/multilevel-ma.html#multilevel-R) from the book [Doing Meta-Analysis in R](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/), @harrer2021doing. 
```{r}
#| echo: false

cite_packages(output = "paragraph", out.dir = ".")
```

```{r results='asis'}
#| echo: false
summary_tables <- lapply(my_dat[1:3], function(x){
  describeBy(x[, c("N", "es", "se_es")], skew = FALSE, group = x$drugType)
})

summary_tables[[4]] <- describe(my_dat[[4]][, c("N", "es", "se_es")], skew = FALSE)
names(summary_tables) <- file_sources
```

# Main analysis
Because some studies provide multiple values we use a three-level Meta-Analysis Model. The nested random effect gets assigned to the grouping variable "study". This means we allow the random intercept to vary across different studys. 
Test statistics and confidence intervals for the fixed effects use a t-distribution.  

```{r}
## Model with level 3 variance set to zero, so we assume all effect sizes to be independent.
## DrugType as moderator variable.
models <- lapply(my_dat[1:3], fit_rma.mv, mods = ~ drugType-1) # -1leave out the intercept. How to interpret? See https://bookdown.org/pingapang9/linear_models_bookdown/chap-categorical.html#the-logic-of-the-f-statistic
models[[1]]

models_test <- lapply(my_dat[1:3], fit_rma.mv, mods = ~ drugType) 
models_test[[1]]

## This essentially the same, put with different parametrization.
## However, now we don't have the difference between both. But possible by:
anova(models[[1]], X = rbind(c(1, -1), c(1, 1)))
## same as second term in : 
models_test[[1]]


## Try out posthoc test
# https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept
# https://www.metafor-project.org/doku.php/tips:multiple_factors_interactions
# https://www.metafor-project.org/doku.php/tips:testing_factors_lincoms
# https://stats.stackexchange.com/questions/324885/easy-post-hoc-tests-when-meta-analyzing-with-the-metafor-package-in-r

library(multcomp)
glht(models[[1]], linfct=rbind())


## Without moderator for the last data set:
models[[4]] <- fit_rma.mv(df = my_dat[[4]])


## Model with level 3 variance set to zero, so we assume all effect sizes to be independent
models_2 <- lapply(my_dat[1:3], fit_rma.mv, mods = ~ drugType, sigma2 = c(0, NA))

## Without moderator for the last data set:
models_2[[4]] <- fit_rma.mv( my_dat[[4]], sigma2 = c(0, NA))


names(models) <- file_sources
names(models_2) <- file_sources

models_summary <- lapply(models, summary)
models_2_summary <- lapply(models_2, summary)
i2 <- lapply(models, var.comp)
```


## Model comparison
```{r, eval = FALSE}
#| echo: false

for(i in 1:length(models)){
  print(anova(models[[i]], models_2[[i]]))
}
```
The nested model doesn't perfom better, so the effects within studies are largely homogneous. However, we know the effects are not independent, so we can keep the three-level model. 

## Results
### Attention
#### Descriptives
```{r}
#| echo: false

summary_tables[["20240115_MABerlin_attention.csv"]]
```

#### Model
```{r}
#| echo: false

models_summary[["20240115_MABerlin_attention.csv"]] 
```

#### $I^2$
```{r}
#| echo: false

i2[["20240115_MABerlin_attention.csv"]] 
```

### Executive
#### Descriptives
```{r}
#| echo: false

summary_tables[["20240115_MABerlin_executive.csv"]]
```

#### Model
```{r}
#| echo: false

models_summary[["20240115_MABerlin_executive.csv"]]
```

#### $I^2$
```{r}
#| echo: false

i2[["20240115_MABerlin_executive.csv"]]
```

### Memory
#### Descriptives
```{r}
#| echo: false

summary_tables[["20240115_MABerlin_memory.csv"]]
```

#### Model
```{r}
#| echo: false

models_summary[["20240115_MABerlin_memory.csv"]]
```

#### $I^2$
```{r}
#| echo: false

i2[["20240115_MABerlin_memory.csv"]]
```

### Microdosing
#### Descriptives
```{r}
#| echo: false

summary_tables[["20240115_MABerlin_microdosing.csv"]]
```

#### Model
```{r}
#| echo: false

models_summary[["20240115_MABerlin_microdosing.csv"]]
```

#### $I^2$
```{r}
#| echo: false

i2[["20240115_MABerlin_microdosing.csv"]]
```

# Sensitivity analyses
In some cases reduntent predictors get dropped because there are not enogh cases with one of the predictors (e.g., sensitivity_psilocybin only inlcudes psychedelics).

```{r}
# Nonconvergence for this analysis, see: http://www.metafor-project.org/doku.php/tips:convergence_problems_rma_mv
my_dat[[3]] <- my_dat[[3]] %>% select(-sensitivity_lsd)

sensitivity_analyses <- lapply(my_dat[1:3], fit_sensitivity, mods = ~ drugType)
sensitivity_analyses[[4]] <- fit_sensitivity(my_dat[[4]])

sensitivity_summary <- lapply(sensitivity_analyses, function(domain){
  lapply(domain, summary)
})
```


## Results

### Attention

#### Speed
```{r}
sensitivity_summary[["20240115_MABerlin_attention.csv"]]["sensitivity_speed"]
```

#### Accuracy
```{r}
sensitivity_summary[["20240115_MABerlin_attention.csv"]]["sensitivity_accuracy"]
```

#### Highest Weight
```{r}
sensitivity_summary[["20240115_MABerlin_attention.csv"]]["sensitivity_highestWeight"]
```

#### Psilocybin
```{r}
sensitivity_summary[["20240115_MABerlin_attention.csv"]]["sensitivity_psilocybin"]
```

#### High Quality
```{r}
sensitivity_summary[["20240115_MABerlin_attention.csv"]]["sensitivity_highQuality"]
```

### Executive

#### Speed
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_speed"]
```

#### Accuracy
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_accuracy"]
```

#### Highest Weight
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_highestWeight"]
```

#### Psilocybin
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_psilocybin"]
```

#### LSD
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_lsd"]
```

#### High Quality
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_highQuality"]
```

### Memory

#### Speed
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_speed"]
```

#### Accuracy
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_accuracy"]
```

#### Highest Weight
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_highestWeight"]
```

#### Psilocybin
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_psilocybin"]
```

#### LSD
Did not converge.
```{r, eval = FALSE}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_lsd"]
```

#### High Quality
```{r}
sensitivity_summary[["20240115_MABerlin_executive.csv"]]["sensitivity_highQuality"]
```

### Microdosing
#### Highest Weight
```{r}
sensitivity_summary[["20240115_MABerlin_microdosing"]]["sensitivity_highestWeight"]
```

#### Psilocybin
```{r}
sensitivity_summary[["20240115_MABerlin_microdosing.csv"]]["sensitivity_psilocybin"]
```


# Interpretation

- `Variance Components`:
    * sigma^2.1 contains the level 3 between-cluster variance.
    * sigma^2.2 shows the variance within clusters (level 2).
- `Test of Moderators`: Indicates differences between the subgroups mdma & psychadelics.  
- `Model Results`
    * `estimate` is our estimated pooled effect. 
    * CAUTION: In case of the analyses with moderator we have an `intercept`, which is the effect size if the drug is mdma. The effect of the psychedlics group can be obtained by adding their estimate value to the intercept. See [here](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/multilevel-ma.html#three-level-subgroup) for interpretation example.  
- `$I^2$`: 
    * $I^2$ quantifies the amount of variation not attributable to sampling error. In three level models, it is split into a part attributable to true effect size differences within clusters (level 2) and between cluster variation (level 3). 
We have 2 $I^2$ values per model quantifying the percentage of total variation associated with either level 2 or level 3. 

# References
